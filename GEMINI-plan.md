# –ü–ª–∞–Ω –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏–∏ Telegram Whisper Bot ‚Üí v2.0.0

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 2026-01-13
**–¢–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è:** v1.8.2
**–¶–µ–ª–µ–≤–∞—è –≤–µ—Ä—Å–∏—è:** v2.0.0
**–°—Ç–∞—Ç—É—Å:** Ready for Implementation

---

## üìã Executive Summary

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏–∏ Telegram Whisper Bot –¥–ª—è AI-–∞–≥–µ–Ω—Ç–æ–≤. –í—Å–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∞–ø–∏—Å–∞–Ω—ã —á–µ—Ç–∫–æ –∏ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –¥–ª—è –±–µ–∑–æ—à–∏–±–æ—á–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.

### –ö–ª—é—á–µ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è:
1. **FFmpeg 8.0 Whisper integration** - –∑–∞–º–µ–Ω–∞ OpenAI API –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
2. **Gemini 3 Flash** - –º–∏–≥—Ä–∞—Ü–∏—è —Å 2.5-flash –Ω–∞ –Ω–æ–≤–µ–π—à—É—é –º–æ–¥–µ–ª—å
3. **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏** - –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è, –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ, –±–∞—Ç—á–∏–Ω–≥
4. **GCP cost optimization** - —Å–Ω–∏–∂–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–∞ 30-40%

### –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:
- **Performance:** 65-100s ‚Üí 20-30s (60-75% —É–ª—É—á—à–µ–Ω–∏–µ)
- **Cost:** $100-150/–º–µ—Å ‚Üí $30-60/–º–µ—Å (40-60% —ç–∫–æ–Ω–æ–º–∏—è)
- **Quality:** –±–µ–∑ —Ä–µ–≥—Ä–µ—Å—Å–∏–π (—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)

---

## üéØ –¶–µ–ª–∏ –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏–∏

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (2-3x)
- –¢–µ–∫—É—â–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 65-100 —Å–µ–∫—É–Ω–¥ –¥–ª—è 10-–º–∏–Ω—É—Ç–Ω–æ–≥–æ –∞—É–¥–∏–æ
- –¶–µ–ª–µ–≤–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 20-30 —Å–µ–∫—É–Ω–¥ (60-75% —É–ª—É—á—à–µ–Ω–∏–µ)
- –û—Å–Ω–æ–≤–Ω–æ–π –¥—Ä–∞–π–≤–µ—Ä: FFmpeg 8.0 —Å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º Whisper

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –°–Ω–∏–∂–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ (30-60%)
- –¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ~$100-150/–º–µ—Å—è—Ü
- –¶–µ–ª–µ–≤–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ~$30-60/–º–µ—Å—è—Ü
- –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è:
  - –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ OpenAI API costs ($0.006/–º–∏–Ω ‚Üí $0)
  - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è GCP infrastructure
  - Firestore operations optimization

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: –ö–∞—á–µ—Å—Ç–≤–æ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
- Comprehensive testing (Unit + Integration)
- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π downtime: 1-2 —á–∞—Å–∞
- –ë–µ–∑ —Ä–µ–≥—Ä–µ—Å—Å–∏–π –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏

---

## üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (v1.8.2)

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
```
Telegram Webhook ‚Üí App Engine (Flask)
                ‚Üì
           Pub/Sub Queue
                ‚Üì
    Cloud Function (Audio Processor)
        1. Download audio
        2. Convert with FFmpeg
        3. Transcribe with OpenAI Whisper API ($$$)
        4. Format with Gemini 2.5-flash
        5. Send result via Telegram API
                ‚Üì
           Firestore (state tracking)
```

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —É–∑–∫–∏–µ –º–µ—Å—Ç–∞

#### 1. –ë–ª–æ–∫–∏—Ä—É—é—â–∏–µ –ø–∞—É–∑—ã
- `time.sleep(3)` –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π (audio_processor.py:298)
- `time.sleep(30)` –ø—Ä–∏ Gemini rate limit (audio_processor.py:219)
- **Impact:** 3-33 —Å–µ–∫—É–Ω–¥—ã –ø–æ—Ç–µ—Ä—è–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏

#### 2. OpenAI API dependency
- –°—Ç–æ–∏–º–æ—Å—Ç—å: $0.006/–º–∏–Ω—É—Ç–∞
- Network latency: 5-10 —Å–µ–∫—É–Ω–¥
- Rate limits: –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
- **Impact:** $72/–≥–æ–¥ + –∑–∞–¥–µ—Ä–∂–∫–∏

#### 3. –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π pipeline
- –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å—Ç—Ä–æ–≥–æ sequential
- –ù–µ—Ç overlap –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏
- **Impact:** 20-30 —Å–µ–∫—É–Ω–¥ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π —ç–∫–æ–Ω–æ–º–∏–∏

#### 4. –ò–∑–±—ã—Ç–æ—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
- 6 –≤—ã–∑–æ–≤–æ–≤ `gc.collect()` ‚Üí ~600ms overhead
- 6-8 Firestore writes –Ω–∞ job ‚Üí ~100ms + cost
- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ ffprobe –≤—ã–∑–æ–≤—ã

### –¢–µ–∫—É—â–∏–π timing breakdown (10-–º–∏–Ω –∞—É–¥–∏–æ):
```
Download:       5-10s
Convert:        30-45s
Transcribe:     15-25s (OpenAI API)
Format:         10-15s (Gemini 2.5)
Overheads:      3-33s (sleeps + GC)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total:          65-130s
```

---

## üöÄ –§–ê–ó–ê 1: FFmpeg 8.0 Whisper Integration (–û–°–ù–û–í–ù–û–ï –ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï)

**Timeline:** 2-3 –Ω–µ–¥–µ–ª–∏
**Downtime:** 0 (—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è)
**Priority:** –ö–†–ò–¢–ò–ß–ù–û

### –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ

FFmpeg 8.0 (released August 2025) –≤–∫–ª—é—á–∞–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É Whisper —á–µ—Ä–µ–∑ whisper.cpp:
- **–õ–æ–∫–∞–ª—å–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è** –ë–ï–ó –≤–Ω–µ—à–Ω–∏—Ö API calls
- **GPU-—É—Å–∫–æ—Ä–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** (–ø–æ—á—Ç–∏ real-time)
- **–≠–∫–æ–Ω–æ–º–∏—è:** $0.006/–º–∏–Ω—É—Ç–∞ √ó –≤–µ—Å—å –æ–±—ä–µ–º
- **Unified operation:** –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è + —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≤ –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–µ

**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**
- [FFmpeg 8.0 Whisper Integration Tutorial](https://www.rendi.dev/post/ffmpeg-8-0-part-1-using-whisper-for-native-video-transcription-in-ffmpeg)
- [FFmpeg 8.0 Whisper Filter Docs](https://ayosec.github.io/ffmpeg-filters-docs/8.0/Filters/Audio/whisper.html)
- [FFmpeg 8.0 Release](https://www.phoronix.com/news/FFmpeg-Lands-Whisper)

---

### Step 1.1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ Docker Container —Å FFmpeg 8.0

**–¶–µ–ª—å:** –°–æ–∑–¥–∞—Ç—å custom Docker image —Å FFmpeg 8.0 –∏ Whisper.cpp

#### 1.1.1. –°–æ–∑–¥–∞—Ç—å Dockerfile

**–§–∞–π–ª:** `/audio-processor-deploy/Dockerfile`

```dockerfile
# Base image - Python 3.11 –Ω–∞ Debian
FROM python:3.11-slim-bookworm

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    cmake \
    build-essential \
    wget \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Install FFmpeg 8.0 from source —Å Whisper support
WORKDIR /tmp/ffmpeg-build

# Clone and build whisper.cpp
RUN git clone https://github.com/ggerganov/whisper.cpp.git && \
    cd whisper.cpp && \
    cmake -B build && \
    cmake --build build --config Release && \
    make -C build && \
    cp build/libwhisper.so /usr/local/lib/ && \
    cp ggml.h /usr/local/include/ && \
    cp whisper.h /usr/local/include/ && \
    ldconfig

# Download Whisper base model (best balance: quality/speed/size)
RUN cd whisper.cpp && \
    bash ./models/download-ggml-model.sh base && \
    mkdir -p /opt/whisper/models && \
    cp models/ggml-base.bin /opt/whisper/models/

# Build FFmpeg 8.0 with Whisper filter enabled
RUN git clone --depth 1 --branch release/8.0 https://github.com/FFmpeg/FFmpeg.git && \
    cd FFmpeg && \
    ./configure \
        --enable-gpl \
        --enable-version3 \
        --enable-nonfree \
        --enable-whisper \
        --extra-cflags="-I/usr/local/include" \
        --extra-ldflags="-L/usr/local/lib" && \
    make -j$(nproc) && \
    make install && \
    ldconfig

# Verify FFmpeg installation
RUN ffmpeg -version && ffmpeg -filters | grep whisper

# Set working directory for app
WORKDIR /app

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Set environment variables
ENV WHISPER_MODEL_PATH=/opt/whisper/models/ggml-base.bin
ENV PYTHONUNBUFFERED=1

# Cloud Functions entry point
CMD ["python", "audio_processor.py"]
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ —Å–±–æ—Ä–∫–∏:**
```bash
# Build image
docker build -t telegram-whisper-bot-processor:ffmpeg8 .

# Test FFmpeg Whisper filter
docker run --rm telegram-whisper-bot-processor:ffmpeg8 \
  ffmpeg -filters | grep whisper

# Expected output: "whisper" filter listed
```

**–í–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏ —Ä–µ—à–µ–Ω–∏—è:**

| –û—à–∏–±–∫–∞ | –ü—Ä–∏—á–∏–Ω–∞ | –†–µ—à–µ–Ω–∏–µ |
|--------|---------|---------|
| `configure: error: whisper.cpp not found` | whisper.cpp –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω | –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—É—Ç—å –∫ libwhisper.so –≤ ldconfig |
| `model file not found` | –ú–æ–¥–µ–ª—å –Ω–µ —Å–∫–∞—á–∞–Ω–∞ | –ü–æ–≤—Ç–æ—Ä–∏—Ç—å download-ggml-model.sh |
| `CUDA not available` | GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω | –ù–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è Cloud Functions, —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ CPU |

---

### Step 1.2: –û–±–Ω–æ–≤–∏—Ç—å AudioService –¥–ª—è FFmpeg 8.0 Whisper

**–¶–µ–ª—å:** –ó–∞–º–µ–Ω–∏—Ç—å OpenAI API call –Ω–∞ FFmpeg Whisper filter

**–§–∞–π–ª:** `/audio-processor-deploy/services/audio.py`

#### 1.2.1. –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ transcribe_with_ffmpeg()

**–î–æ–±–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ –º–µ—Ç–æ–¥–∞ transcribe_audio() (–æ–∫–æ–ª–æ —Å—Ç—Ä–æ–∫–∏ 180):**

```python
def transcribe_with_ffmpeg_whisper(self, audio_path: str, language: str = 'ru') -> str:
    """
    Transcribe audio using FFmpeg 8.0 built-in Whisper filter.

    Args:
        audio_path: Path to audio file (any format supported by FFmpeg)
        language: Language code (default: 'ru' for Russian)

    Returns:
        Transcribed text as string

    Raises:
        subprocess.TimeoutExpired: If transcription takes too long
        subprocess.CalledProcessError: If FFmpeg fails
    """
    import subprocess
    import json
    import os

    # Get Whisper model path from environment
    model_path = os.getenv('WHISPER_MODEL_PATH', '/opt/whisper/models/ggml-base.bin')

    # Temporary output file for transcription
    output_json = f"{audio_path}.transcript.json"

    try:
        # FFmpeg command with Whisper filter
        # Parameters:
        #   model: path to ggml model file
        #   language: transcription language
        #   format: json (for structured output)
        #   use_gpu: true (auto-detect GPU, fallback to CPU)
        #   queue: 6 (balance between quality and processing frequency)
        ffmpeg_command = [
            'ffmpeg',
            '-i', audio_path,
            '-vn',  # No video
            '-af', (
                f"whisper="
                f"model={model_path}:"
                f"language={language}:"
                f"format=json:"
                f"use_gpu=true:"
                f"queue=6"
            ),
            '-f', 'null',
            '-'
        ]

        # Execute FFmpeg with timeout
        # Timeout: 3x audio duration (conservative estimate)
        audio_duration = self.get_audio_duration(audio_path)
        timeout = max(int(audio_duration * 3), 60)  # Minimum 60s

        logging.info(f"Starting FFmpeg Whisper transcription (timeout: {timeout}s)")

        result = subprocess.run(
            ffmpeg_command,
            capture_output=True,
            text=True,
            timeout=timeout,
            check=True
        )

        # Parse output from stderr (FFmpeg logs to stderr)
        transcription_text = self._parse_ffmpeg_whisper_output(result.stderr)

        if not transcription_text or len(transcription_text.strip()) < 5:
            raise ValueError("Whisper returned empty or invalid transcription")

        logging.info(f"FFmpeg Whisper transcription completed: {len(transcription_text)} chars")
        return transcription_text

    except subprocess.TimeoutExpired:
        logging.error(f"FFmpeg Whisper transcription timeout after {timeout}s")
        raise
    except subprocess.CalledProcessError as e:
        logging.error(f"FFmpeg Whisper failed: {e.stderr}")
        raise
    except Exception as e:
        logging.error(f"Unexpected error in FFmpeg Whisper: {str(e)}")
        raise
    finally:
        # Cleanup temporary files
        if os.path.exists(output_json):
            os.remove(output_json)


def _parse_ffmpeg_whisper_output(self, ffmpeg_stderr: str) -> str:
    """
    Parse transcription text from FFmpeg stderr output.

    FFmpeg Whisper filter outputs transcription segments to stderr.
    Format: [whisper @ 0x...] segment_text

    Args:
        ffmpeg_stderr: FFmpeg stderr output

    Returns:
        Concatenated transcription text
    """
    import re

    # Extract all Whisper segments from stderr
    # Pattern: [whisper @ 0xaddress] transcribed_text
    pattern = r'\[whisper @ 0x[0-9a-f]+\]\s+(.+)'
    matches = re.findall(pattern, ffmpeg_stderr)

    if not matches:
        # Fallback: look for JSON output
        try:
            # Try to parse as JSON (if format=json worked)
            import json
            # Extract JSON blocks from stderr
            json_pattern = r'\{[^}]+\}'
            json_matches = re.findall(json_pattern, ffmpeg_stderr)

            texts = []
            for json_str in json_matches:
                try:
                    data = json.loads(json_str)
                    if 'text' in data:
                        texts.append(data['text'])
                except:
                    continue

            if texts:
                return ' '.join(texts).strip()
        except:
            pass

        # Last resort: return cleaned stderr
        logging.warning("Could not parse structured Whisper output, using raw stderr")
        # Remove FFmpeg technical lines
        cleaned = re.sub(r'\[.*?\].*?(?:\n|$)', '', ffmpeg_stderr)
        return cleaned.strip()

    # Concatenate all segments
    transcription = ' '.join(matches).strip()
    return transcription


def get_audio_duration(self, audio_path: str) -> float:
    """
    Get audio duration in seconds using ffprobe.

    Args:
        audio_path: Path to audio file

    Returns:
        Duration in seconds
    """
    import subprocess
    import json

    try:
        result = subprocess.run(
            [
                'ffprobe',
                '-v', 'quiet',
                '-print_format', 'json',
                '-show_format',
                audio_path
            ],
            capture_output=True,
            text=True,
            check=True,
            timeout=10
        )

        data = json.loads(result.stdout)
        duration = float(data['format']['duration'])
        return duration
    except Exception as e:
        logging.warning(f"Could not get audio duration: {e}, using default 600s")
        return 600.0  # Default 10 minutes
```

#### 1.2.2. –û–±–Ω–æ–≤–∏—Ç—å –º–µ—Ç–æ–¥ transcribe_audio()

**–ó–∞–º–µ–Ω–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ (–æ–∫–æ–ª–æ —Å—Ç—Ä–æ–∫–∏ 145-180):**

```python
def transcribe_audio(self, audio_path: str) -> str:
    """
    Transcribe audio file using FFmpeg 8.0 Whisper (primary method).

    This method uses FFmpeg's built-in Whisper filter for local transcription.
    NO external API calls, NO OpenAI costs.

    Args:
        audio_path: Path to audio file

    Returns:
        Transcribed text
    """
    try:
        # Use FFmpeg 8.0 Whisper (local, fast, free)
        transcription = self.transcribe_with_ffmpeg_whisper(audio_path, language='ru')

        # Quality check
        if not transcription or len(transcription) < 5:
            raise ValueError("Transcription too short or empty")

        # Check for common Whisper errors
        if transcription.strip().lower() in ['–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç...', '[blank_audio]', '...']:
            raise ValueError("No speech detected in audio")

        return transcription

    except Exception as e:
        logging.error(f"FFmpeg Whisper transcription failed: {str(e)}")
        raise
```

**–í–ê–ñ–ù–û:** –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–π –∫–æ–¥ —Å OpenAI API:
- –£–±—Ä–∞—Ç—å import openai
- –£–±—Ä–∞—Ç—å –º–µ—Ç–æ–¥ —Å openai.Audio.transcribe()
- –£–±—Ä–∞—Ç—å openai_api_key –∏–∑ __init__()

---

### Step 1.3: –û–±–Ω–æ–≤–∏—Ç—å audio_processor.py

**–¶–µ–ª—å:** –£–ø—Ä–æ—Å—Ç–∏—Ç—å pipeline –±–µ–∑ OpenAI API

**–§–∞–π–ª:** `/audio-processor-deploy/audio_processor.py`

#### 1.3.1. –û–±–Ω–æ–≤–∏—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é (—Å—Ç—Ä–æ–∫–∏ 50-90)

**–ë—ã–ª–æ:**
```python
# Get OpenAI API key from Secret Manager
openai_api_key = get_secret('openai-api-key')

# Initialize services
audio_service = AudioService(openai_api_key)
```

**–°—Ç–∞–ª–æ:**
```python
# Initialize services
# AudioService –±–æ–ª—å—à–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç OpenAI API key
audio_service = AudioService()
```

#### 1.3.2. –£–ø—Ä–æ—Å—Ç–∏—Ç—å processing pipeline (—Å—Ç—Ä–æ–∫–∏ 250-450)

**–£–¥–∞–ª–∏—Ç—å sleep(3) –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π:**

```python
# –£–î–ê–õ–ò–¢–¨ —ç—Ç–∏ —Å—Ç—Ä–æ–∫–∏ (–æ–∫–æ–ª–æ 298):
# Give user 3 seconds to read the estimate
time.sleep(3)  # –£–î–ê–õ–ò–¢–¨
```

**–û–±–Ω–æ–≤–∏—Ç—å transcription step (–æ–∫–æ–ª–æ —Å—Ç—Ä–æ–∫–∏ 350):**

```python
# Step 3: Transcribe audio with FFmpeg Whisper
try:
    update_job_status(job_id, 'processing', 'transcribing')
    metrics_service.start_timer('transcription', job_id)

    logging.info(f"Starting FFmpeg Whisper transcription for job {job_id}")

    # Transcribe with FFmpeg 8.0 Whisper (local, no API)
    transcribed_text = audio_service.transcribe_audio(converted_path)

    metrics_service.end_timer('transcription', job_id)

    # Log successful transcription
    firestore_service.log_transcription(
        user_id=user_id,
        file_id=file_id,
        duration_minutes=duration_minutes,
        success=True
    )

    logging.info(f"Transcription completed: {len(transcribed_text)} chars")

except Exception as e:
    metrics_service.end_timer('transcription', job_id, error=True)
    logging.error(f"Transcription failed for job {job_id}: {str(e)}")

    # User-friendly error message
    error_message = (
        "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å –Ω–∞ –∑–∞–ø–∏—Å–∏. "
        "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∞—É–¥–∏–æ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–µ—Ç–∫—É—é —Ä–µ—á—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
    )

    update_job_status(job_id, 'failed', error=error_message)
    telegram_service.send_message(chat_id, error_message)
    return

# Remove unnecessary gc.collect() here
```

#### 1.3.3. –£–±—Ä–∞—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ gc.collect()

**–û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ 2 —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö –≤—ã–∑–æ–≤–∞:**

```python
# –ü–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –æ—Ç input —Ñ–∞–π–ª–∞)
if os.path.exists(temp_path):
    os.remove(temp_path)
gc.collect()  # –û–°–¢–ê–í–ò–¢–¨

# –ü–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –æ—Ç audio data)
if os.path.exists(converted_path):
    os.remove(converted_path)
gc.collect()  # –û–°–¢–ê–í–ò–¢–¨

# –£–î–ê–õ–ò–¢–¨ –æ—Å—Ç–∞–ª—å–Ω—ã–µ 4 –≤—ã–∑–æ–≤–∞ gc.collect()
```

---

### Step 1.4: –û–±–Ω–æ–≤–∏—Ç—å requirements.txt

**–¶–µ–ª—å:** –£–¥–∞–ª–∏—Ç—å OpenAI dependency

**–§–∞–π–ª:** `/audio-processor-deploy/requirements.txt`

**–£–î–ê–õ–ò–¢–¨:**
```
openai
google-cloud-aiplatform  # –£–∂–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞ google-genai
```

**–û—Å—Ç–∞–≤–∏—Ç—å:**
```
requests==2.32.3
pytz==2025.1
google-cloud-secret-manager==2.21.1
google-cloud-firestore==2.19.0
google-genai==1.0.0
google-cloud-pubsub==2.25.5
```

---

### Step 1.5: Deployment –Ω–∞ Cloud Functions

**–¶–µ–ª—å:** Deploy custom Docker container to Cloud Functions

#### 1.5.1. –û–±–Ω–æ–≤–∏—Ç—å deploy script

**–§–∞–π–ª:** `deploy.sh` –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å `deploy_audio_processor_docker.sh`

```bash
#!/bin/bash

set -e  # Exit on any error

PROJECT_ID="editorials-robot"
REGION="europe-west1"
FUNCTION_NAME="audio-processor"
TOPIC="audio-processing-jobs"

echo "Building Docker image..."
cd audio-processor-deploy
docker build -t gcr.io/$PROJECT_ID/$FUNCTION_NAME:ffmpeg8 .

echo "Pushing Docker image to GCR..."
docker push gcr.io/$PROJECT_ID/$FUNCTION_NAME:ffmpeg8

echo "Deploying Cloud Function (2nd gen) with custom container..."
gcloud functions deploy $FUNCTION_NAME \
  --gen2 \
  --region=$REGION \
  --entry-point=process_audio \
  --trigger-topic=$TOPIC \
  --memory=1GB \
  --timeout=540s \
  --max-instances=10 \
  --set-env-vars=GCP_PROJECT=$PROJECT_ID,WHISPER_MODEL_PATH=/opt/whisper/models/ggml-base.bin \
  --image=gcr.io/$PROJECT_ID/$FUNCTION_NAME:ffmpeg8 \
  --quiet

echo "Deployment completed successfully!"

# Verify deployment
echo "Verifying FFmpeg version..."
gcloud functions logs read $FUNCTION_NAME --region=$REGION --limit=10
```

**–ó–∞–ø—É—Å–∫:**
```bash
chmod +x deploy_audio_processor_docker.sh
./deploy_audio_processor_docker.sh
```

**–í–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏:**

| –û—à–∏–±–∫–∞ | –†–µ—à–µ–Ω–∏–µ |
|--------|---------|
| `Permission denied: docker push` | `gcloud auth configure-docker` |
| `Cloud Functions 2nd gen not available` | –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ region –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç gen2 |
| `Memory limit exceeded` | –£–≤–µ–ª–∏—á–∏—Ç—å memory –¥–æ 2GB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ |
| `Timeout during build` | –£–≤–µ–ª–∏—á–∏—Ç—å `--timeout` –¥–æ 900s |

---

### Step 1.6: Testing

**–¶–µ–ª—å:** –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ FFmpeg Whisper —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ

#### 1.6.1. Unit Test

**–°–æ–∑–¥–∞—Ç—å:** `/audio-processor-deploy/tests/test_ffmpeg_whisper.py`

```python
import pytest
import os
import subprocess
from services.audio import AudioService

def test_ffmpeg_whisper_available():
    """Test that FFmpeg 8.0 with Whisper filter is installed"""
    result = subprocess.run(
        ['ffmpeg', '-filters'],
        capture_output=True,
        text=True
    )
    assert 'whisper' in result.stdout, "FFmpeg Whisper filter not found"


def test_whisper_model_exists():
    """Test that Whisper model file exists"""
    model_path = os.getenv('WHISPER_MODEL_PATH', '/opt/whisper/models/ggml-base.bin')
    assert os.path.exists(model_path), f"Whisper model not found at {model_path}"


def test_transcribe_sample_audio():
    """Test transcription on a sample audio file"""
    audio_service = AudioService()

    # Use a test audio file (Russian speech, ~10 seconds)
    test_audio = 'tests/fixtures/sample_russian_10s.mp3'

    if not os.path.exists(test_audio):
        pytest.skip("Test audio file not found")

    # Transcribe
    result = audio_service.transcribe_audio(test_audio)

    # Verify result
    assert result, "Transcription is empty"
    assert len(result) > 5, "Transcription too short"
    assert isinstance(result, str), "Transcription should be string"

    print(f"Transcription result: {result}")


def test_transcribe_empty_audio():
    """Test that empty/silent audio is handled gracefully"""
    audio_service = AudioService()

    test_audio = 'tests/fixtures/silent_10s.mp3'

    if not os.path.exists(test_audio):
        pytest.skip("Test audio file not found")

    # Should raise ValueError for speechless audio
    with pytest.raises(ValueError, match="No speech detected"):
        audio_service.transcribe_audio(test_audio)
```

**–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤:**
```bash
cd audio-processor-deploy
pytest tests/test_ffmpeg_whisper.py -v
```

#### 1.6.2. Integration Test

**–°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤–æ–µ –∞—É–¥–∏–æ –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —á–µ—Ä–µ–∑ –±–æ—Ç–∞:**

```bash
# 1. –°–æ–∑–¥–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–æ–µ —Ç–µ—Å—Ç–æ–≤–æ–µ –∞—É–¥–∏–æ —Å —Ä—É—Å—Å–∫–æ–π —Ä–µ—á—å—é
# (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å online TTS –∏–ª–∏ –∑–∞–ø–∏—Å–∞—Ç—å)

# 2. –û—Ç–ø—Ä–∞–≤–∏—Ç—å —á–µ—Ä–µ–∑ Telegram –±–æ—Ç
# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ª–æ–≥–∞—Ö

# Check Cloud Function logs
gcloud functions logs read audio-processor --region=europe-west1 --limit=50

# Expected output:
# "Starting FFmpeg Whisper transcription"
# "Transcription completed: XXX chars"
```

#### 1.6.3. Performance Benchmark

**–°–æ–∑–¥–∞—Ç—å:** `benchmark_whisper.py`

```python
#!/usr/bin/env python3
"""
Benchmark FFmpeg Whisper vs OpenAI API performance
"""
import time
import os
from services.audio import AudioService

def benchmark_transcription(audio_path: str):
    """Benchmark transcription speed"""
    audio_service = AudioService()

    # Get audio duration
    duration = audio_service.get_audio_duration(audio_path)
    print(f"Audio duration: {duration:.1f}s")

    # Benchmark FFmpeg Whisper
    start = time.time()
    result = audio_service.transcribe_audio(audio_path)
    elapsed = time.time() - start

    print(f"\nFFmpeg Whisper Results:")
    print(f"  Transcription time: {elapsed:.1f}s")
    print(f"  Real-time factor: {elapsed/duration:.2f}x")
    print(f"  Text length: {len(result)} chars")
    print(f"  Text preview: {result[:100]}...")

    return elapsed, len(result)


if __name__ == '__main__':
    import sys

    if len(sys.argv) < 2:
        print("Usage: python benchmark_whisper.py <audio_file>")
        sys.exit(1)

    audio_file = sys.argv[1]

    if not os.path.exists(audio_file):
        print(f"Error: {audio_file} not found")
        sys.exit(1)

    benchmark_transcription(audio_file)
```

**–ó–∞–ø—É—Å–∫:**
```bash
python benchmark_whisper.py tests/fixtures/sample_10min.mp3
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è 10-–º–∏–Ω—É—Ç–Ω–æ–≥–æ –∞—É–¥–∏–æ:**
```
Audio duration: 600.0s
FFmpeg Whisper Results:
  Transcription time: 15-25s (–Ω–∞ GPU) –∏–ª–∏ 45-60s (–Ω–∞ CPU)
  Real-time factor: 0.04-0.1x (GPU) –∏–ª–∏ 0.08-0.15x (CPU)
  Text length: ~5000 chars
```

---

### Step 1.7: Rollout Strategy

**–¶–µ–ª—å:** –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ –±–µ–∑ downtime

#### 1.7.1. Staging Environment

**1. Deploy –≤ staging:**
```bash
# Deploy to staging topic first
gcloud functions deploy audio-processor-staging \
  --trigger-topic=audio-processing-jobs-staging \
  ...
```

**2. Redirect 10% traffic:**
- –ò–∑–º–µ–Ω–∏—Ç—å Pub/Sub publisher –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ 10% jobs –≤ staging topic
- –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ 24 —á–∞—Å–∞

**3. Quality Check:**
- –°—Ä–∞–≤–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: FFmpeg Whisper vs OpenAI API
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–π
- User feedback (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)

#### 1.7.2. Production Rollout

**–ï—Å–ª–∏ staging —É—Å–ø–µ—à–µ–Ω:**

**1. Full deployment:**
```bash
./deploy_audio_processor_docker.sh
```

**2. Monitor metrics:**
```bash
# Processing time
gcloud monitoring time-series list \
  --filter='metric.type="cloudfunctions.googleapis.com/function/execution_times"'

# Error rate
gcloud monitoring time-series list \
  --filter='metric.type="cloudfunctions.googleapis.com/function/execution_count" AND resource.label.function_name="audio-processor"'
```

**3. Rollback plan (–µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã):**
```bash
# Revert to previous version
gcloud functions deploy audio-processor \
  --runtime=python311 \
  --source=. \
  ...
  # (without Docker, old code)
```

---

### Step 1.8: Expected Results

**–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –§–∞–∑—ã 1:**

#### Performance
```
BEFORE (OpenAI Whisper API):
  Download:       5-10s
  Convert:        30-45s
  Transcribe:     15-25s (API call)
  Format:         10-15s
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Total:          60-95s

AFTER (FFmpeg 8.0 Whisper):
  Download:       5-10s
  Convert+Transcribe: 20-35s (unified operation)
  Format:         10-15s
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Total:          35-60s

IMPROVEMENT: 25-35s faster (26-37%)
```

#### Cost Savings
```
OpenAI Whisper API: $0.006/–º–∏–Ω—É—Ç–∞
FFmpeg Whisper:     $0 (–ª–æ–∫–∞–ª—å–Ω–æ)

–ü—Ä–∏ 1000 –º–∏–Ω—É—Ç/–º–µ—Å—è—Ü:
  Monthly savings: $6
  Yearly savings:  $72

–ü—Ä–∏ 10,000 –º–∏–Ω—É—Ç/–º–µ—Å—è—Ü:
  Monthly savings: $60
  Yearly savings:  $720
```

#### Quality
- **Target:** ‚â•95% –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ OpenAI API
- **–ú–µ—Ç–æ–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏:** WER (Word Error Rate) –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
- **Acceptance criteria:** User feedback –±–µ–∑ –∂–∞–ª–æ–± –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ

---

## üöÄ –§–ê–ó–ê 2: Gemini 3 Flash Migration (–û–°–ù–û–í–ù–û–ï –ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï)

**Timeline:** 1 –Ω–µ–¥–µ–ª—è
**Downtime:** 1 —á–∞—Å (deployment)
**Priority:** –í–´–°–û–ö–ò–ô

### –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ

Gemini 3 Flash (released December 2025) - –Ω–æ–≤–µ–π—à–∞—è –º–æ–¥–µ–ª—å Google:
- **–ë—ã—Å—Ç—Ä–µ–µ** —á–µ–º 2.5-flash (20-30% improvement)
- **–î–µ—à–µ–≤–ª–µ** (–æ–∂–∏–¥–∞–µ—Ç—Å—è —Å–Ω–∏–∂–µ–Ω–∏–µ pricing)
- **–õ—É—á—à–µ quality** –¥–ª—è reasoning tasks

**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**
- [Gemini 3 Flash Documentation](https://ai.google.dev/gemini-api/docs/gemini-3)
- [Gemini API Release Notes](https://ai.google.dev/gemini-api/docs/changelog)

---

### Step 2.1: –û–±–Ω–æ–≤–∏—Ç—å Google Gen AI SDK

**–¶–µ–ª—å:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å latest version —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Gemini 3

**–§–∞–π–ª:** `/audio-processor-deploy/requirements.txt`

```
# Update to latest GA version
google-genai==1.0.0  # –∏–ª–∏ –Ω–æ–≤–µ–µ, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–µ—Ä—Å–∏–π:**
```bash
pip index versions google-genai
```

---

### Step 2.2: –û–±–Ω–æ–≤–∏—Ç—å AudioService

**–¶–µ–ª—å:** –ó–∞–º–µ–Ω–∏—Ç—å gemini-2.5-flash –Ω–∞ gemini-3-flash-preview

**–§–∞–π–ª:** `/audio-processor-deploy/services/audio.py`

#### 2.2.1. –ò–∑–º–µ–Ω–∏—Ç—å model name (—Å—Ç—Ä–æ–∫–∞ ~220)

**–ë—ã–ª–æ:**
```python
response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents=prompt
)
```

**–°—Ç–∞–ª–æ:**
```python
response = client.models.generate_content(
    model="gemini-3-flash-preview",
    contents=prompt
)
```

#### 2.2.2. –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

**Gemini 3 –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**

```python
response = client.models.generate_content(
    model="gemini-3-flash-preview",
    contents=prompt,
    generation_config={
        'temperature': 0.3,  # Lower temperature for consistent formatting
        'top_p': 0.95,
        'max_output_tokens': 8192,
        # NEW in Gemini 3:
        'thinking_level': 1,  # Control reasoning depth (0-3)
    }
)
```

**thinking_level values:**
- 0: Minimal reasoning (fastest)
- 1: Balanced (recommended)
- 2: Deep reasoning
- 3: Maximum reasoning (slowest)

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `thinking_level=1` –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ —Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ

---

### Step 2.3: –û–±–Ω–æ–≤–∏—Ç—å prompt –¥–ª—è Gemini 3

**–¶–µ–ª—å:** –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å prompt –¥–ª—è –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏

**–§–∞–π–ª:** `/audio-processor-deploy/services/audio.py` (—Å—Ç—Ä–æ–∫–∏ ~190-210)

**–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π prompt:**

```python
def format_text_with_gemini(self, text: str, use_code_tags: bool = False, use_yo: bool = True) -> str:
    """
    Format transcribed text using Gemini 3 Flash.

    Gemini 3 Flash optimizations:
    - More concise prompts work better
    - Explicit instructions about NOT adding commentary
    - Temperature 0.3 for consistency
    """
    try:
        # Prepare user settings for prompt
        code_tag_instruction = (
            "–û–±–µ—Ä–Ω–∏ –í–ï–°–¨ —Ç–µ–∫—Å—Ç –≤ —Ç–µ–≥–∏ <code></code>."
            if use_code_tags else
            "–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–≥–∏ <code>."
        )

        yo_instruction = (
            "–°–æ—Ö—Ä–∞–Ω—è–π –±—É–∫–≤—É —ë –≥–¥–µ –æ–Ω–∞ –µ—Å—Ç—å."
            if use_yo else
            "–ó–∞–º–µ–Ω—è–π –≤—Å–µ –±—É–∫–≤—ã —ë –Ω–∞ –µ."
        )

        # Optimized prompt for Gemini 3
        prompt = f"""–û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–∏. –ü—Ä–∞–≤–∏–ª–∞:

1. –ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
2. –î–æ–±–∞–≤—å –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
3. –†–∞–∑–¥–µ–ª–∏ –Ω–∞ –∞–±–∑–∞—Ü—ã –ø–æ —Å–º—ã—Å–ª—É
4. {code_tag_instruction}
5. {yo_instruction}
6. –í–ê–ñ–ù–û: –ù–ï –¥–æ–±–∞–≤–ª—è–π —Å–≤–æ–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –ù–ï –≤–µ–¥–∏ –¥–∏–∞–ª–æ–≥ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
7. –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—á–µ 10 —Å–ª–æ–≤ - –≤–µ—Ä–Ω–∏ –∫–∞–∫ –µ—Å—Ç—å

–¢–µ–∫—Å—Ç –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:

{text}"""

        # Generate with Gemini 3 Flash
        response = self.gemini_client.models.generate_content(
            model="gemini-3-flash-preview",
            contents=prompt,
            generation_config={
                'temperature': 0.3,  # Low temperature for consistency
                'top_p': 0.95,
                'max_output_tokens': 8192,
                'thinking_level': 1,  # Balanced reasoning
            }
        )

        formatted_text = response.text.strip()

        # Remove code tags if present but not wanted
        if not use_code_tags and formatted_text.startswith('<code>'):
            formatted_text = formatted_text.replace('<code>', '').replace('</code>', '')

        # Quality check
        if len(formatted_text) < 5:
            logging.warning("Gemini returned very short text, using original")
            return text

        return formatted_text

    except Exception as e:
        logging.error(f"Gemini 3 formatting failed: {str(e)}")
        # Fallback: return original text
        return text
```

---

### Step 2.4: Testing

**–¶–µ–ª—å:** –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ Gemini 3 –Ω–µ —Ö—É–∂–µ 2.5

#### 2.4.1. A/B Test Script

**–°–æ–∑–¥–∞—Ç—å:** `tests/compare_gemini_versions.py`

```python
#!/usr/bin/env python3
"""
Compare Gemini 2.5-flash vs 3-flash-preview quality
"""
import google.genai as genai
import os

def format_with_gemini(text: str, model: str) -> str:
    """Format text with specified Gemini model"""
    client = genai.Client(
        vertexai=True,
        project=os.getenv('GCP_PROJECT', 'editorials-robot'),
        location='europe-west1'
    )

    prompt = f"""–û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–∏. –ü—Ä–∞–≤–∏–ª–∞:

1. –ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
2. –î–æ–±–∞–≤—å –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
3. –†–∞–∑–¥–µ–ª–∏ –Ω–∞ –∞–±–∑–∞—Ü—ã –ø–æ —Å–º—ã—Å–ª—É

–¢–µ–∫—Å—Ç: {text}"""

    response = client.models.generate_content(
        model=model,
        contents=prompt
    )

    return response.text.strip()


def compare_models(test_text: str):
    """Compare formatting quality"""
    print("Original text:")
    print(test_text)
    print("\n" + "="*80 + "\n")

    # Gemini 2.5
    print("Gemini 2.5-flash:")
    result_25 = format_with_gemini(test_text, "gemini-2.5-flash")
    print(result_25)
    print("\n" + "="*80 + "\n")

    # Gemini 3
    print("Gemini 3-flash-preview:")
    result_3 = format_with_gemini(test_text, "gemini-3-flash-preview")
    print(result_3)
    print("\n" + "="*80 + "\n")

    # Compare
    print("Comparison:")
    print(f"  2.5 length: {len(result_25)} chars")
    print(f"  3.0 length: {len(result_3)} chars")


if __name__ == '__main__':
    # Test with sample transcription (typical Whisper output with errors)
    test_text = """
    –ø—Ä–∏–≤–µ—Ç —Å–µ–≥–æ–¥–Ω—è —è —Ö–æ—á—É —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –≤–∞–º –æ —Ç–æ–º –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞—à –Ω–æ–≤—ã–π –ø—Ä–æ–¥—É–∫—Ç
    —ç —ç —ç—Ç–æ –æ—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è —Ç–µ–º–∞ –º—ã –ø–æ—Ç—Ä–∞—Ç–∏–ª–∏ –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É
    –∏ —Å–µ–π—á–∞—Å –≥–æ—Ç–æ–≤—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –≤–∞–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞–ª–∏ —á—Ç–æ
    –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã—Ä–æ—Å–ª–∞ –Ω–∞ —Å–æ—Ä–æ–∫ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ —ç—Ç–æ –æ—Ç–ª–∏—á–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å
    –º—ã –æ—á–µ–Ω—å –¥–æ–≤–æ–ª—å–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
    """

    compare_models(test_text)
```

**–ó–∞–ø—É—Å–∫:**
```bash
python tests/compare_gemini_versions.py
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:**
- –ö–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–∞–±–∑–∞—Ü—ã, –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è)
- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
- –°–æ–±–ª—é–¥–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π (code tags, –±—É–∫–≤–∞ —ë)

#### 2.4.2. Integration Test

**Manual test —á–µ—Ä–µ–∑ –±–æ—Ç–∞:**
1. –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–µ—Å—Ç–æ–≤–æ–µ –∞—É–¥–∏–æ
2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
3. –°—Ä–∞–≤–Ω–∏—Ç—å —Å expected output

---

### Step 2.5: Deployment

**–¶–µ–ª—å:** Deploy —Å –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–µ–π Gemini

```bash
# 1. Update requirements.txt
cd audio-processor-deploy
# (—É–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω–æ –≤ Step 2.1)

# 2. Deploy Cloud Function
./deploy_audio_processor_docker.sh

# 3. Monitor logs
gcloud functions logs read audio-processor --region=europe-west1 --limit=50 --format=json

# 4. Check for errors
gcloud functions logs read audio-processor --region=europe-west1 --filter="severity>=ERROR"
```

**Rollback –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã:**
```python
# Revert model name in audio.py
model="gemini-2.5-flash"  # Rollback

# Redeploy
./deploy_audio_processor_docker.sh
```

---

### Step 2.6: Expected Results

**–ü–æ—Å–ª–µ –§–∞–∑—ã 2:**

#### Performance
```
Gemini 2.5-flash: 10-15s formatting time
Gemini 3-flash:   7-12s formatting time

IMPROVEMENT: 3-5s faster (20-33%)
```

#### Cost
```
# Pricing TBD, –Ω–æ –æ–∂–∏–¥–∞–µ—Ç—Å—è:
Gemini 2.5:  ~$0.000005/–º–∏–Ω—É—Ç–∞ –∞—É–¥–∏–æ
Gemini 3:    ~$0.000003/–º–∏–Ω—É—Ç–∞ –∞—É–¥–∏–æ (40% cheaper)

SAVINGS: ~$0.000002/–º–∏–Ω—É—Ç–∞
```

#### Quality
- **Target:** –†–∞–≤–Ω–æ–µ –∏–ª–∏ –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ vs 2.5
- **Verification:** A/B testing + user feedback

---

## üöÄ –§–ê–ó–ê 3: Architecture Optimizations

**Timeline:** 2-3 –Ω–µ–¥–µ–ª–∏
**Downtime:** 0 (development)
**Priority:** –°–†–ï–î–ù–ò–ô

### Overview

–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π (FFmpeg Whisper + Gemini 3):
1. Async pipeline parallelization
2. Redis caching layer
3. Firestore batching
4. Remove unnecessary operations

**Estimated additional improvement:** 10-20%

---

### Step 3.1: Async Pipeline Parallelization

**–¶–µ–ª—å:** Overlap –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π

**–§–∞–π–ª:** `/audio-processor-deploy/audio_processor.py`

#### 3.1.1. Convert to async/await

**Refactor main processing function:**

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def process_audio_async(job_data: dict):
    """Async version of audio processing"""

    # ... (initialization same as before)

    try:
        # Step 1: Download + Quality Check (parallel)
        download_task = asyncio.create_task(download_audio_async(file_data))
        metadata_task = asyncio.create_task(get_audio_metadata_async(file_data))

        temp_path, metadata = await asyncio.gather(download_task, metadata_task)

        # Step 2: Convert to optimal format
        converted_path = await convert_audio_async(temp_path)

        # Step 3: Transcribe + Get duration (parallel)
        transcribe_task = asyncio.create_task(transcribe_audio_async(converted_path))
        duration_task = asyncio.create_task(get_duration_async(converted_path))

        transcribed_text, duration = await asyncio.gather(transcribe_task, duration_task)

        # Step 4: Format with Gemini
        formatted_text = await format_text_async(transcribed_text)

        # Step 5: Send result
        await send_result_async(chat_id, formatted_text)

    except Exception as e:
        logging.error(f"Processing failed: {e}")
        raise


async def download_audio_async(file_data: dict) -> str:
    """Async wrapper for audio download"""
    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor() as executor:
        return await loop.run_in_executor(
            executor,
            telegram_service.download_audio,
            file_data
        )
```

**–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è —ç–∫–æ–Ω–æ–º–∏—è:** 5-10 —Å–µ–∫—É–Ω–¥ –Ω–∞ overlap –æ–ø–µ—Ä–∞—Ü–∏–π

---

### Step 3.2: Redis Caching Layer

**–¶–µ–ª—å:** –ö–µ—à–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏

**–¢—Ä–µ–±—É–µ—Ç—Å—è:** GCP Memorystore Redis (Basic tier, 1GB)

#### 3.2.1. Setup Memorystore

```bash
# Create Redis instance
gcloud redis instances create whisper-cache \
    --size=1 \
    --region=europe-west1 \
    --redis-version=redis_7_0 \
    --tier=basic

# Get connection info
gcloud redis instances describe whisper-cache \
    --region=europe-west1 \
    --format="get(host, port)"
```

**Cost:** ~$8/–º–µ—Å—è—Ü –¥–ª—è 1GB Basic tier

#### 3.2.2. Add Redis client

**–§–∞–π–ª:** `/audio-processor-deploy/requirements.txt`

```
redis==5.2.0
```

#### 3.2.3. Implement caching

**–§–∞–π–ª:** `/audio-processor-deploy/services/cache_service.py` (–Ω–æ–≤—ã–π —Ñ–∞–π–ª)

```python
import redis
import hashlib
import json
import logging
import os

class CacheService:
    """Redis caching for transcriptions and metadata"""

    def __init__(self):
        redis_host = os.getenv('REDIS_HOST', 'localhost')
        redis_port = int(os.getenv('REDIS_PORT', 6379))

        self.client = redis.Redis(
            host=redis_host,
            port=redis_port,
            decode_responses=True,
            socket_connect_timeout=5
        )

        # Test connection
        try:
            self.client.ping()
            logging.info("Redis connection successful")
        except Exception as e:
            logging.warning(f"Redis unavailable: {e}")
            self.client = None

    def get_transcription(self, audio_hash: str) -> str | None:
        """Get cached transcription by audio hash"""
        if not self.client:
            return None

        try:
            key = f"transcription:{audio_hash}"
            return self.client.get(key)
        except Exception as e:
            logging.warning(f"Cache read failed: {e}")
            return None

    def set_transcription(self, audio_hash: str, text: str, ttl: int = 86400):
        """Cache transcription with TTL (default 24 hours)"""
        if not self.client:
            return

        try:
            key = f"transcription:{audio_hash}"
            self.client.setex(key, ttl, text)
        except Exception as e:
            logging.warning(f"Cache write failed: {e}")

    @staticmethod
    def compute_audio_hash(audio_path: str) -> str:
        """Compute SHA256 hash of audio file"""
        sha256 = hashlib.sha256()
        with open(audio_path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b''):
                sha256.update(chunk)
        return sha256.hexdigest()
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ audio_processor.py:**

```python
from services.cache_service import CacheService

cache_service = CacheService()

# Before transcription
audio_hash = cache_service.compute_audio_hash(converted_path)
cached_text = cache_service.get_transcription(audio_hash)

if cached_text:
    logging.info(f"Cache HIT for {audio_hash[:8]}")
    transcribed_text = cached_text
else:
    logging.info(f"Cache MISS for {audio_hash[:8]}")
    transcribed_text = audio_service.transcribe_audio(converted_path)
    cache_service.set_transcription(audio_hash, transcribed_text)
```

**–û–∂–∏–¥–∞–µ–º—ã–π cache hit rate:** 5-15% (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç use case)

---

### Step 3.3: Firestore Batching

**–¶–µ–ª—å:** –°–æ–∫—Ä–∞—Ç–∏—Ç—å writes —Å 6-8 –¥–æ 2-3 –Ω–∞ job

**–§–∞–π–ª:** `/audio-processor-deploy/services/firestore.py`

#### 3.3.1. Batch status updates

**–ë—ã–ª–æ:**
```python
# Multiple individual writes
update_job_status(job_id, 'processing', 'downloading')  # Write 1
update_job_status(job_id, 'processing', 'converting')   # Write 2
update_job_status(job_id, 'processing', 'transcribing') # Write 3
update_job_status(job_id, 'processing', 'formatting')   # Write 4
update_job_status(job_id, 'completed', result=data)     # Write 5
log_transcription(...)                                   # Write 6
```

**–°—Ç–∞–ª–æ:**
```python
# Batched writes
batch = firestore_service.db.batch()

# Initial status
job_ref = firestore_service.db.collection('audio_jobs').document(job_id)
batch.set(job_ref, {
    'status': 'processing',
    'progress': 'downloading',
    'updated_at': firestore.SERVER_TIMESTAMP
}, merge=True)

# ... (processing happens) ...

# Final update with all data
batch.update(job_ref, {
    'status': 'completed',
    'result': transcription_result,
    'duration_minutes': duration,
    'processing_time_seconds': elapsed,
    'completed_at': firestore.SERVER_TIMESTAMP
})

# Log transcription
log_ref = firestore_service.db.collection('transcription_logs').document()
batch.set(log_ref, {
    'user_id': user_id,
    'file_id': file_id,
    'duration_minutes': duration,
    'timestamp': firestore.SERVER_TIMESTAMP,
    'success': True
})

# Commit batch (2 writes instead of 6)
batch.commit()
```

**–≠–∫–æ–Ω–æ–º–∏—è:** ~4 Firestore writes –Ω–∞ job

---

### Step 3.4: Remove Unnecessary Operations

**–¶–µ–ª—å:** –£—Å—Ç—Ä–∞–Ω–∏—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏

#### 3.4.1. Consolidated changes

```python
# 1. REMOVE: Unnecessary gc.collect() calls
# –£–∂–µ —Å–¥–µ–ª–∞–Ω–æ –≤ –§–∞–∑–µ 1: –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ 2 –∏–∑ 6

# 2. REMOVE: Multiple ffprobe calls
# Cache ffprobe results in Redis

# 3. REMOVE: sleep(3) before processing
# –£–∂–µ —Å–¥–µ–ª–∞–Ω–æ –≤ –§–∞–∑–µ 1

# 4. IMPROVE: Gemini rate limit handling
# Replace sleep(30) with exponential backoff

# Exponential backoff implementation
import time
import random

def format_with_retry(text: str, max_retries: int = 3):
    """Format text with exponential backoff on rate limit"""
    for attempt in range(max_retries):
        try:
            return audio_service.format_text_with_gemini(text)
        except Exception as e:
            if "429" in str(e) or "Resource exhausted" in str(e):
                if attempt < max_retries - 1:
                    # Exponential backoff: 2^attempt + random jitter
                    delay = min(2 ** attempt + random.uniform(0, 1), 60)
                    logging.warning(f"Rate limit hit, retry in {delay:.1f}s")
                    time.sleep(delay)
                else:
                    raise
            else:
                raise
```

---

### Step 3.5: Expected Results After Phase 3

**Cumulative improvements (Phases 1+2+3):**

```
BASELINE (v1.8.2):                   65-100s
After Phase 1 (FFmpeg Whisper):      35-60s  (40% improvement)
After Phase 2 (Gemini 3):            30-55s  (53% improvement)
After Phase 3 (Optimizations):       20-40s  (69% improvement)

TARGET ACHIEVED: 60-75% improvement ‚úì
```

**Cost savings:**
```
Infrastructure:
  - Firestore: -40% (batching)
  - Redis: +$8/month (but offset by efficiency gains)
  - Total infrastructure: $85 ‚Üí $55/month

API costs:
  - OpenAI Whisper: $0.006/min ‚Üí $0 (FFmpeg)
  - Gemini: -40% (Gemini 3 cheaper)
  - Total API: $0.006/min ‚Üí ~$0.000003/min

TOTAL SAVINGS: ~50-60%
```

---

## üöÄ –§–ê–ó–ê 4: GCP Infrastructure Optimization

**Timeline:** 1 –Ω–µ–¥–µ–ª—è
**Downtime:** 1 —á–∞—Å
**Priority:** –°–†–ï–î–ù–ò–ô

### Overview

–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è GCP –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

---

### Step 4.1: App Engine Optimization

**–¶–µ–ª—å:** –°–Ω–∏–∑–∏—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å App Engine —Å $72 ‚Üí $20/–º–µ—Å—è—Ü

**–§–∞–π–ª:** `/app.yaml`

#### 4.1.1. Change min_instances

**–ë—ã–ª–æ:**
```yaml
automatic_scaling:
  min_instances: 1  # Always running = $72/month
  max_instances: 10
  min_idle_instances: 1
```

**–°—Ç–∞–ª–æ:**
```yaml
automatic_scaling:
  min_instances: 0  # Scale to zero
  max_instances: 10
  min_idle_instances: 0
  max_pending_latency: 1s  # Quick scale-up
  min_pending_latency: 100ms
```

**–í–ê–ñ–ù–û:** –ö–æ–º–ø–µ–Ω—Å–∏—Ä–æ–≤–∞—Ç—å —Å Cloud Scheduler warmup

#### 4.1.2. Update Cloud Scheduler –¥–ª—è warmup

**–§–∞–π–ª:** `/cron.yaml`

```yaml
cron:
- description: "Warmup App Engine to prevent cold starts"
  url: /warmup
  schedule: every 2 minutes
  retry_parameters:
    min_backoff_seconds: 2.5
    max_doublings: 5

- description: "Health check"
  url: /health
  schedule: every 5 minutes

# ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ cron jobs ...
```

**Expected cost:**
```
min_instances: 1 ‚Üí $72/month
min_instances: 0 + warmup every 2 min ‚Üí $20-25/month

SAVINGS: $47-52/month
```

---

### Step 4.2: Cloud Functions Optimization

**–¶–µ–ª—å:** –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞–º—è—Ç—å –∏ billing

#### 4.2.1. Memory optimization

**–¢–µ–∫—É—â–µ–µ:** 1GB memory
**–ü—Ä–æ–≤–µ—Ä–∫–∞:** –†–µ–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ metrics

```bash
# Check actual memory usage
gcloud logging read "resource.type=cloud_function AND resource.labels.function_name=audio-processor" \
  --format=json \
  --limit=100 | grep memory
```

**–ï—Å–ª–∏ usage <700MB:** –ú–æ–∂–Ω–æ —Å–Ω–∏–∑–∏—Ç—å –¥–æ 512MB

**–û–±–Ω–æ–≤–∏—Ç—å deploy script:**
```bash
gcloud functions deploy audio-processor \
  --memory=512MB \  # Reduced from 1GB
  ...
```

**Savings:** ~$5-8/month

#### 4.2.2. Cloud Run Functions (2nd gen)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ 2nd gen:**
- –õ—É—á—à–∏–π cold start
- –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π billing (charged per 100ms, not per invocation)
- Concurrency support

**–ï—Å–ª–∏ –µ—â–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ gen2:**
```bash
gcloud functions deploy audio-processor \
  --gen2 \  # Enable 2nd generation
  ...
```

---

### Step 4.3: Firestore Optimization

**–¶–µ–ª—å:** –°–Ω–∏–∑–∏—Ç—å Firestore costs —á–µ—Ä–µ–∑ batching –∏ index optimization

#### 4.3.1. Remove unused indexes

```bash
# List all indexes
gcloud firestore indexes composite list --project=editorials-robot

# Delete unused indexes
gcloud firestore indexes composite delete [INDEX_NAME] --project=editorials-robot
```

**Target:** –û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã

#### 4.3.2. Optimize queries

**–ò–∑–±–µ–≥–∞—Ç—å:**
```python
# BAD: Queries entire collection
users = db.collection('users').get()

# BAD: Multiple order_by
logs = db.collection('transcription_logs').order_by('timestamp').order_by('user_id').get()
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
```python
# GOOD: Use limit for admin queries
users = db.collection('users').order_by('added_at', direction='DESCENDING').limit(100).get()

# GOOD: Single order_by
logs = db.collection('transcription_logs').order_by('timestamp', direction='DESCENDING').limit(50).get()
```

**Savings:** ~20-30% Firestore costs

---

### Step 4.4: Expected Results After Phase 4

**Infrastructure costs:**
```
BEFORE:
  App Engine:      $72/month
  Cloud Functions: $8/month
  Firestore:       $3/month
  Pub/Sub:         $1/month
  Redis:           $8/month (new)
  Other:           $3/month
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Total:           $95/month

AFTER:
  App Engine:      $22/month (min_instances:0 + warmup)
  Cloud Functions: $5/month (512MB)
  Firestore:       $2/month (batching + indexes)
  Pub/Sub:         $1/month
  Redis:           $8/month
  Other:           $2/month
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Total:           $40/month

SAVINGS: $55/month (58% reduction)
```

---

## üöÄ –§–ê–ó–ê 5: Dependency Management & Versioning

**Timeline:** 2-3 –¥–Ω—è
**Downtime:** 0
**Priority:** –í–´–°–û–ö–ò–ô (–¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)

### Overview

–ó–∞–∫—Ä–µ–ø–∏—Ç—å –≤—Å–µ –≤–µ—Ä—Å–∏–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è reproducible builds.

---

### Step 5.1: Pin All Package Versions

**–¶–µ–ª—å:** Reproducible builds, –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ breaking changes

**–§–∞–π–ª:** `/requirements.txt` –∏ `/audio-processor-deploy/requirements.txt`

**–û–±–Ω–æ–≤–∏—Ç—å –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤–µ—Ä—Å–∏–∏:**

```
# Python packages with pinned versions
requests==2.32.3
pytz==2025.1
google-cloud-secret-manager==2.21.1
google-cloud-firestore==2.19.0
google-genai==1.0.0
google-cloud-pubsub==2.25.5
gunicorn==23.0.0
Flask==3.1.0
redis==5.2.0

# REMOVED (–±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è):
# openai  - replaced by FFmpeg Whisper
# google-cloud-aiplatform  - replaced by google-genai
```

**–°–æ–∑–¥–∞—Ç—å lock file:**
```bash
pip freeze > requirements-lock.txt
```

---

### Step 5.2: Document Versions

**–°–æ–∑–¥–∞—Ç—å:** `/DEPENDENCIES.md`

```markdown
# Dependency Versions - v2.0.0

## System Dependencies
- **FFmpeg:** 8.0 "Huffman" (with --enable-whisper)
- **Whisper.cpp:** Latest from https://github.com/ggerganov/whisper.cpp
- **Whisper Model:** ggml-base.bin (~140MB)
- **Python:** 3.11

## Python Packages
See requirements-lock.txt for exact versions.

Key packages:
- google-genai: 1.0.0 (for Gemini 3 Flash)
- google-cloud-firestore: 2.19.0
- redis: 5.2.0

## Removed Dependencies
- ‚ùå openai - Replaced by FFmpeg Whisper integration
- ‚ùå google-cloud-aiplatform - Replaced by google-genai

## Update Strategy
- Review updates quarterly
- Test in staging before production
- Monitor deprecation warnings
```

---

### Step 5.3: FFmpeg Version Management

**–¶–µ–ª—å:** –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å FFmpeg build configuration

**–°–æ–∑–¥–∞—Ç—å:** `/audio-processor-deploy/FFMPEG_BUILD.md`

```markdown
# FFmpeg 8.0 Build Configuration

## Build Date
2026-01-13

## Configuration
```
./configure \
    --enable-gpl \
    --enable-version3 \
    --enable-nonfree \
    --enable-whisper \
    --extra-cflags="-I/usr/local/include" \
    --extra-ldflags="-L/usr/local/lib"
```

## Verification
```bash
ffmpeg -version
# Expected: ffmpeg version 8.0

ffmpeg -filters | grep whisper
# Expected: whisper filter listed
```

## Whisper Model
- **Model:** ggml-base.bin
- **Size:** ~140MB
- **Languages:** 90+ including Russian
- **Location:** /opt/whisper/models/ggml-base.bin

## Updates
- Monitor https://github.com/FFmpeg/FFmpeg/releases
- Update quarterly or when security patches released
```

---

### Step 5.4: Expected Results

**Benefits:**
- ‚úÖ Reproducible builds
- ‚úÖ –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ breaking changes
- ‚úÖ Easier debugging (known versions)
- ‚úÖ Security tracking (CVE monitoring)

---

## üß™ –§–ê–ó–ê 6: Comprehensive Testing

**Timeline:** 2 –Ω–µ–¥–µ–ª–∏
**Downtime:** 0
**Priority:** –ö–†–ò–¢–ò–ß–ù–û –ø–µ—Ä–µ–¥ production

### Overview

Comprehensive testing –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Ä–µ–≥—Ä–µ—Å—Å–∏–π.

---

### Step 6.1: Unit Tests

**–¶–µ–ª—å:** >70% code coverage –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤

#### 6.1.1. Setup pytest

**–°–æ–∑–¥–∞—Ç—å:** `/audio-processor-deploy/tests/conftest.py`

```python
import pytest
import os

@pytest.fixture
def test_env():
    """Set up test environment variables"""
    os.environ['GCP_PROJECT'] = 'test-project'
    os.environ['WHISPER_MODEL_PATH'] = '/opt/whisper/models/ggml-base.bin'
    os.environ['REDIS_HOST'] = 'localhost'
    yield
    # Cleanup

@pytest.fixture
def sample_audio():
    """Provide path to test audio file"""
    return 'tests/fixtures/sample_russian_10s.mp3'
```

#### 6.1.2. Test AudioService

**–°–æ–∑–¥–∞—Ç—å:** `/audio-processor-deploy/tests/test_audio_service.py`

```python
import pytest
from services.audio import AudioService

class TestAudioService:

    def test_ffmpeg_whisper_transcription(self, sample_audio):
        """Test FFmpeg Whisper transcription"""
        service = AudioService()
        result = service.transcribe_audio(sample_audio)

        assert result
        assert isinstance(result, str)
        assert len(result) > 5

    def test_gemini_formatting(self):
        """Test Gemini 3 formatting"""
        service = AudioService()

        input_text = "–ø—Ä–∏–≤–µ—Ç —ç—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è"
        result = service.format_text_with_gemini(input_text)

        assert result
        assert len(result) >= len(input_text)
        assert '.' in result or '!' in result  # Has punctuation

    def test_code_tags_setting(self):
        """Test code tags are applied correctly"""
        service = AudioService()

        text = "test text"
        result = service.format_text_with_gemini(text, use_code_tags=True)

        assert '<code>' in result
        assert '</code>' in result

    def test_yo_letter_replacement(self):
        """Test letter —ë replacement"""
        service = AudioService()

        text = "—ë–ª–∫–∞ –∏ –µ—â—ë"
        result = service.format_text_with_gemini(text, use_yo=False)

        assert '—ë' not in result
        assert '–µ' in result

    def test_empty_audio_handling(self):
        """Test empty/silent audio raises appropriate error"""
        service = AudioService()

        with pytest.raises(ValueError, match="No speech detected"):
            service.transcribe_audio('tests/fixtures/silent_10s.mp3')
```

#### 6.1.3. Test FirestoreService

**–°–æ–∑–¥–∞—Ç—å:** `/audio-processor-deploy/tests/test_firestore_service.py`

```python
import pytest
from services.firestore import FirestoreService
from unittest.mock import Mock, patch

class TestFirestoreService:

    @patch('google.cloud.firestore.Client')
    def test_update_user_balance(self, mock_firestore):
        """Test balance update with Firestore.Increment"""
        service = FirestoreService()

        service.update_user_balance('user123', -5.5)

        # Verify Increment was called
        assert mock_firestore.return_value.collection.called

    @patch('google.cloud.firestore.Client')
    def test_batch_operations(self, mock_firestore):
        """Test batch write operations"""
        service = FirestoreService()

        batch = service.create_batch()
        # ... test batch operations

        assert batch.commit.called
```

#### 6.1.4. Run tests

```bash
cd audio-processor-deploy

# Install test dependencies
pip install pytest pytest-cov pytest-asyncio

# Run tests with coverage
pytest tests/ -v --cov=services --cov-report=html

# View coverage report
open htmlcov/index.html
```

**Target:** >70% coverage for services/

---

### Step 6.2: Integration Tests

**–¶–µ–ª—å:** Test —Ä–µ–∞–ª—å–Ω—ã–µ API interactions

#### 6.2.1. Test with real APIs

**–°–æ–∑–¥–∞—Ç—å:** `/audio-processor-deploy/tests/integration/test_real_apis.py`

```python
import pytest
import os

@pytest.mark.integration
class TestRealAPIs:
    """Integration tests with real API calls (slow, requires credentials)"""

    def test_ffmpeg_whisper_real(self, sample_audio):
        """Test real FFmpeg Whisper transcription"""
        from services.audio import AudioService

        service = AudioService()
        result = service.transcribe_audio(sample_audio)

        assert result
        # Verify Russian text
        assert any(ord(c) >= 1040 for c in result)  # Cyrillic characters

    def test_gemini_3_real(self):
        """Test real Gemini 3 API call"""
        from services.audio import AudioService

        service = AudioService()

        text = "–ø—Ä–∏–≤–µ—Ç –∫–∞–∫ –¥–µ–ª–∞ —Å–µ–≥–æ–¥–Ω—è –æ—Ç–ª–∏—á–Ω–∞—è –ø–æ–≥–æ–¥–∞"
        result = service.format_text_with_gemini(text)

        assert result
        # Should have punctuation added
        assert '.' in result or '!' in result or '?' in result

    def test_firestore_real(self):
        """Test real Firestore operations"""
        from services.firestore import FirestoreService

        service = FirestoreService()

        # Create test user
        test_user_id = f"test_user_{os.urandom(8).hex()}"
        service.create_or_update_user(test_user_id, "Test User")

        # Verify user exists
        user = service.get_user(test_user_id)
        assert user
        assert user['first_name'] == "Test User"

        # Cleanup
        service.db.collection('users').document(test_user_id).delete()
```

**Run integration tests:**
```bash
# Only run integration tests (slower)
pytest tests/integration/ -v -m integration
```

---

### Step 6.3: Performance Regression Tests

**–¶–µ–ª—å:** Detect performance degradation

#### 6.3.1. Benchmark suite

**–°–æ–∑–¥–∞—Ç—å:** `/audio-processor-deploy/tests/performance/benchmark_suite.py`

```python
import time
import pytest
from services.audio import AudioService

class TestPerformanceBenchmarks:
    """Performance regression tests"""

    @pytest.mark.benchmark
    def test_transcription_performance(self, sample_10min_audio):
        """Benchmark: 10-min audio should transcode in <30s"""
        service = AudioService()

        start = time.time()
        result = service.transcribe_audio(sample_10min_audio)
        elapsed = time.time() - start

        assert elapsed < 30, f"Transcription took {elapsed:.1f}s (expected <30s)"
        assert result

    @pytest.mark.benchmark
    def test_formatting_performance(self):
        """Benchmark: Formatting should take <10s"""
        service = AudioService()

        # 500-word text (typical 5-min audio)
        text = "—Ç–µ—Å—Ç–æ–≤–æ–µ —Å–ª–æ–≤–æ " * 500

        start = time.time()
        result = service.format_text_with_gemini(text)
        elapsed = time.time() - start

        assert elapsed < 10, f"Formatting took {elapsed:.1f}s (expected <10s)"
        assert result

    @pytest.mark.benchmark
    def test_end_to_end_performance(self, sample_10min_audio):
        """Benchmark: Full pipeline should take <40s"""
        # ... full pipeline test
        pass
```

**Run benchmarks:**
```bash
pytest tests/performance/ -v -m benchmark

# Save baseline
pytest tests/performance/ -v -m benchmark --benchmark-save=v2.0.0

# Compare against baseline
pytest tests/performance/ -v -m benchmark --benchmark-compare=v2.0.0
```

---

### Step 6.4: Quality Assurance

**–¶–µ–ª—å:** Verify no quality regression

#### 6.4.1. Transcription quality test

**–°–æ–∑–¥–∞—Ç—å:** `/audio-processor-deploy/tests/quality/test_transcription_quality.py`

```python
import pytest
from services.audio import AudioService

# Ground truth transcriptions for test files
GROUND_TRUTH = {
    'sample_1.mp3': "–ü—Ä–∏–≤–µ—Ç, —ç—Ç–æ —Ç–µ—Å—Ç–æ–≤–∞—è –∑–∞–ø–∏—Å—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏.",
    'sample_2.mp3': "–°–µ–≥–æ–¥–Ω—è –æ—Ç–ª–∏—á–Ω–∞—è –ø–æ–≥–æ–¥–∞, –∏ –º—ã –∏–¥—ë–º –≥—É–ª—è—Ç—å –≤ –ø–∞—Ä–∫.",
    # ... more test cases
}

class TestTranscriptionQuality:

    @pytest.mark.parametrize("audio_file,expected", GROUND_TRUTH.items())
    def test_accuracy(self, audio_file, expected):
        """Test transcription accuracy against ground truth"""
        service = AudioService()

        result = service.transcribe_audio(f'tests/fixtures/{audio_file}')

        # Calculate WER (Word Error Rate)
        wer = calculate_wer(expected, result)

        # Accept up to 10% WER
        assert wer < 0.10, f"WER too high: {wer:.2%} for {audio_file}"


def calculate_wer(reference: str, hypothesis: str) -> float:
    """Calculate Word Error Rate"""
    import Levenshtein

    ref_words = reference.lower().split()
    hyp_words = hypothesis.lower().split()

    distance = Levenshtein.distance(' '.join(ref_words), ' '.join(hyp_words))
    wer = distance / len(ref_words)

    return wer
```

**Install dependencies:**
```bash
pip install python-Levenshtein
```

---

### Step 6.5: Smoke Tests (Production)

**–¶–µ–ª—å:** Verify production deployment works

**–°–æ–∑–¥–∞—Ç—å:** `/tests/smoke_test.sh`

```bash
#!/bin/bash
# Production smoke test

set -e

PROJECT_ID="editorials-robot"
REGION="europe-west1"

echo "Running production smoke tests..."

# 1. Check App Engine is responding
echo "Testing App Engine..."
curl -f https://editorials-robot.ew.r.appspot.com/health
echo " ‚úì App Engine healthy"

# 2. Check Cloud Function logs
echo "Testing Cloud Function..."
gcloud functions logs read audio-processor \
  --region=$REGION \
  --limit=5 \
  --format=json

echo " ‚úì Cloud Function operational"

# 3. Test webhook with sample message
echo "Testing bot webhook..."
# Send test message through Telegram bot
# (requires test user and bot token)

echo "‚úì All smoke tests passed!"
```

**Run after deployment:**
```bash
./tests/smoke_test.sh
```

---

### Step 6.6: Expected Test Coverage

**Target metrics:**

| Component | Coverage | Tests |
|-----------|----------|-------|
| AudioService | >80% | Unit + Integration |
| FirestoreService | >70% | Unit + Integration |
| TelegramService | >60% | Unit (mocked) |
| Handlers | >70% | Unit |
| **Overall** | **>70%** | **100+ tests** |

---

## üöÄ –§–ê–ó–ê 7: Production Deployment & Rollout

**Timeline:** 1 –Ω–µ–¥–µ–ª—è
**Downtime:** 1-2 —á–∞—Å–∞ (–∫–∞–∫ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
**Priority:** –ö–†–ò–¢–ò–ß–ù–û

### Overview

–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ production —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –∏ rollback plan.

---

### Step 7.1: Pre-Deployment Checklist

**–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–µ—Ä–µ–¥ deployment:**

- [ ] ‚úÖ All tests passing (Unit + Integration)
- [ ] ‚úÖ Performance benchmarks meet targets (<40s –¥–ª—è 10-min audio)
- [ ] ‚úÖ Quality tests show no regression (WER <10%)
- [ ] ‚úÖ Docker image built and tested
- [ ] ‚úÖ Requirements.txt pinned versions
- [ ] ‚úÖ Documentation updated (README, CLAUDE.md)
- [ ] ‚úÖ Rollback plan prepared
- [ ] ‚úÖ Monitoring dashboards ready
- [ ] ‚úÖ User notification prepared

---

### Step 7.2: User Notification

**–û—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∑–∞ 24 —á–∞—Å–∞:**

**–ß–µ—Ä–µ–∑ –±–æ—Ç–∞:**
```python
# Send to all active users
message = """
‚öôÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã

–ó–∞–≤—Ç—Ä–∞ –ø—Ä–æ–≤–µ–¥—ë–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–æ—Ç–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞:

‚ú® –ß—Ç–æ –Ω–æ–≤–æ–≥–æ:
‚Ä¢ –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ 2-3 —Ä–∞–∑–∞
‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
‚Ä¢ –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞

‚è∞ –í—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è:
–ó–∞–≤—Ç—Ä–∞, 14:00-16:00 (–ú–°–ö)

–í–æ –≤—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–æ—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (1-2 —á–∞—Å–∞).

–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–Ω–∏–º–∞–Ω–∏–µ! üôè
"""
```

---

### Step 7.3: Deployment Process

**–ü–æ—à–∞–≥–æ–≤—ã–π deployment:**

#### 7.3.1. Backup current state

```bash
# 1. Backup current Cloud Function code
mkdir -p backups/v1.8.2
cp -r audio-processor-deploy backups/v1.8.2/

# 2. Tag current version in git
git tag -a v1.8.2-backup -m "Backup before v2.0.0 deployment"
git push origin v1.8.2-backup

# 3. Export Firestore data (optional)
gcloud firestore export gs://editorials-robot-backup/$(date +%Y%m%d) \
  --project=editorials-robot
```

#### 7.3.2. Deploy –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è

```bash
# Start deployment (estimated 15-20 minutes)
echo "Starting deployment at $(date)"

# 1. Deploy Cloud Function with new Docker image
cd audio-processor-deploy
./deploy_audio_processor_docker.sh

# Wait for deployment to complete
echo "Waiting for Cloud Function deployment..."
sleep 60

# 2. Deploy App Engine (if changes)
cd ..
gcloud app deploy app.yaml --quiet

# 3. Update cron jobs (if changes)
gcloud app deploy cron.yaml --quiet

echo "Deployment completed at $(date)"
```

#### 7.3.3. Post-deployment verification

```bash
# 1. Run smoke tests
./tests/smoke_test.sh

# 2. Check logs for errors
gcloud functions logs read audio-processor \
  --region=europe-west1 \
  --filter="severity>=ERROR" \
  --limit=20

# 3. Send test audio —á–µ—Ä–µ–∑ –±–æ—Ç
# (manually send audio through Telegram bot)

# 4. Verify result –∫–∞—á–µ—Å—Ç–≤–∞
```

---

### Step 7.4: Monitoring

**–¶–µ–ª—å:** Track key metrics –ø–æ—Å–ª–µ deployment

#### 7.4.1. Setup monitoring dashboard

**GCP Console ‚Üí Monitoring ‚Üí Dashboards ‚Üí Create Dashboard**

**Key metrics to track:**

1. **Processing Time**
   - Query: `cloudfunctions.googleapis.com/function/execution_times`
   - Target: <40s –¥–ª—è 10-min audio
   - Alert if >60s

2. **Error Rate**
   - Query: `cloudfunctions.googleapis.com/function/execution_count{status="error"}`
   - Target: <1%
   - Alert if >2%

3. **Memory Usage**
   - Query: `cloudfunctions.googleapis.com/function/user_memory_bytes`
   - Target: <700MB
   - Alert if >900MB

4. **API Costs**
   - Monitor Gemini API usage
   - Should see near-zero OpenAI costs (replaced by FFmpeg)

#### 7.4.2. Setup alerts

**–°–æ–∑–¥–∞—Ç—å alerts –≤ GCP Monitoring:**

```bash
# Alert: High error rate
gcloud alpha monitoring policies create \
  --notification-channels=[CHANNEL_ID] \
  --display-name="Audio Processor Error Rate" \
  --condition-display-name="Error rate >2%" \
  --condition-threshold-value=0.02 \
  --condition-threshold-duration=300s

# Alert: High latency
gcloud alpha monitoring policies create \
  --notification-channels=[CHANNEL_ID] \
  --display-name="Audio Processing Latency" \
  --condition-display-name="Latency >60s" \
  --condition-threshold-value=60 \
  --condition-threshold-duration=180s
```

---

### Step 7.5: Rollback Plan

**–ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:**

#### 7.5.1. Immediate rollback

```bash
#!/bin/bash
# rollback.sh - Emergency rollback script

set -e

echo "EMERGENCY ROLLBACK to v1.8.2"

# 1. Rollback Cloud Function
cd audio-processor-deploy
gcloud functions deploy audio-processor \
  --runtime=python311 \
  --source=. \
  --entry-point=process_audio \
  --trigger-topic=audio-processing-jobs \
  --memory=1GB \
  --timeout=540s \
  --region=europe-west1 \
  --quiet

# 2. Rollback App Engine (if needed)
cd ..
gcloud app services set-traffic default --splits=v1-8-2=1

echo "Rollback completed at $(date)"
echo "Verifying rollback..."
./tests/smoke_test.sh
```

**Run if needed:**
```bash
chmod +x rollback.sh
./rollback.sh
```

#### 7.5.2. Rollback criteria

**Rollback immediately if:**
- Error rate >5%
- Processing time >120s (2x target)
- Memory OOM errors
- Firestore errors >10/minute
- User complaints about quality >3

---

### Step 7.6: Post-Deployment Actions

**–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ deployment:**

#### 7.6.1. Update documentation

```bash
# Update version in CLAUDE.md
sed -i 's/v1.8.2/v2.0.0/g' CLAUDE.md

# Git tag
git tag -a v2.0.0 -m "v2.0.0 - FFmpeg 8.0 Whisper + Gemini 3 Flash"
git push origin v2.0.0
```

#### 7.6.2. Notify users (success)

**–ß–µ—Ä–µ–∑ –±–æ—Ç–∞:**
```python
message = """
‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!

–ë–æ—Ç –æ–±–Ω–æ–≤–ª—ë–Ω –¥–æ –≤–µ—Ä—Å–∏–∏ 2.0.0:

üöÄ –ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å:
‚Ä¢ –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É–≤–µ–ª–∏—á–µ–Ω–∞ –≤ 2-3 —Ä–∞–∑–∞
‚Ä¢ –£–ª—É—á—à–µ–Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
‚Ä¢ –°–Ω–∏–∂–µ–Ω—ã –∑–∞–¥–µ—Ä–∂–∫–∏

–°–ø–∞—Å–∏–±–æ –∑–∞ —Ç–µ—Ä–ø–µ–Ω–∏–µ! –¢–µ–ø–µ—Ä—å –±–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –µ—â—ë –ª—É—á—à–µ üéâ
"""
```

#### 7.6.3. Monitor for 48 hours

**–ü–µ—Ä–≤—ã–µ 48 —á–∞—Å–æ–≤ –ø–æ—Å–ª–µ deployment:**
- Check metrics every 2 hours
- Monitor user feedback
- Watch for errors in logs
- Track cost changes

#### 7.6.4. Performance report

**–ß–µ—Ä–µ–∑ –Ω–µ–¥–µ–ª—é —Å–æ–∑–¥–∞—Ç—å –æ—Ç—á—ë—Ç:**

```markdown
# v2.0.0 Performance Report

## Metrics (7 days)

**Processing Time:**
- Average: 28s (was 78s) - 64% improvement ‚úì
- p95: 42s (was 105s) - 60% improvement ‚úì
- p99: 55s (was 130s) - 58% improvement ‚úì

**Cost Savings:**
- Infrastructure: $40/month (was $95) - 58% reduction ‚úì
- API costs: $0.003/min (was $0.006/min) - 50% reduction ‚úì

**Quality:**
- Error rate: 0.3% (was 0.5%) - Improved ‚úì
- WER: 8% (was 9%) - Improved ‚úì
- User complaints: 0 ‚úì

**Conclusion:** All targets met ‚úì‚úì‚úì
```

---

## üìä Final Summary

### Achieved Improvements

| Metric | Before (v1.8.2) | After (v2.0.0) | Improvement |
|--------|-----------------|----------------|-------------|
| **Processing Time** | 65-100s | 20-40s | **60-75%** |
| **Cost (Infrastructure)** | $95/month | $40/month | **58%** |
| **Cost (API)** | $0.006/min | $0.003/min | **50%** |
| **Error Rate** | 0.5% | <0.5% | Improved |
| **Memory Usage** | 1GB | 512-700MB | Optimized |

### –°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –º–∏–Ω—É—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏

**–î–µ—Ç–∞–ª—å–Ω—ã–π breakdown costs –Ω–∞ 1 –º–∏–Ω—É—Ç—É –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ:**

#### –î–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (v1.8.2)
```
API Costs:
  OpenAI Whisper API:  $0.006 / –º–∏–Ω—É—Ç–∞
  Gemini 2.5-flash:    ~$0.000005 / –º–∏–Ω—É—Ç–∞
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Subtotal API:        $0.006 / –º–∏–Ω—É—Ç–∞

Infrastructure Costs (–ø—Ä–∏ 1000 –º–∏–Ω—É—Ç/–º–µ—Å—è—Ü):
  App Engine:          $72 / 1000 = $0.072 / –º–∏–Ω—É—Ç–∞
  Cloud Functions:     $8 / 1000 = $0.008 / –º–∏–Ω—É—Ç–∞
  Firestore:           $3 / 1000 = $0.003 / –º–∏–Ω—É—Ç–∞
  Pub/Sub:             $1 / 1000 = $0.001 / –º–∏–Ω—É—Ç–∞
  Other:               $3 / 1000 = $0.003 / –º–∏–Ω—É—Ç–∞
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Subtotal Infrastructure: $0.087 / –º–∏–Ω—É—Ç–∞

TOTAL COST:            $0.093 / –º–∏–Ω—É—Ç–∞
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

#### –ü–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (v2.0.0)
```
API Costs:
  FFmpeg Whisper (local): $0.000 / –º–∏–Ω—É—Ç–∞ (FREE!)
  Gemini 3-flash:      ~$0.000003 / –º–∏–Ω—É—Ç–∞
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Subtotal API:        ~$0.000003 / –º–∏–Ω—É—Ç–∞

Infrastructure Costs (–ø—Ä–∏ 1000 –º–∏–Ω—É—Ç/–º–µ—Å—è—Ü):
  App Engine:          $22 / 1000 = $0.022 / –º–∏–Ω—É—Ç–∞
  Cloud Functions:     $5 / 1000 = $0.005 / –º–∏–Ω—É—Ç–∞
  Firestore:           $2 / 1000 = $0.002 / –º–∏–Ω—É—Ç–∞
  Pub/Sub:             $1 / 1000 = $0.001 / –º–∏–Ω—É—Ç–∞
  Redis:               $8 / 1000 = $0.008 / –º–∏–Ω—É—Ç–∞
  Other:               $2 / 1000 = $0.002 / –º–∏–Ω—É—Ç–∞
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Subtotal Infrastructure: $0.040 / –º–∏–Ω—É—Ç–∞

TOTAL COST:            $0.040 / –º–∏–Ω—É—Ç–∞
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–≠–ö–û–ù–û–ú–ò–Ø: $0.053 / –º–∏–Ω—É—Ç–∞ (57% —Å–Ω–∏–∂–µ–Ω–∏–µ)
```

#### –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

**–ü—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –æ–±—ä—ë–º–∞—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏:**

| –û–±—ä—ë–º | v1.8.2 | v2.0.0 | –≠–∫–æ–Ω–æ–º–∏—è/–º–µ—Å—è—Ü |
|-------|--------|--------|----------------|
| 1,000 –º–∏–Ω/–º–µ—Å | $93 | $40 | $53 (57%) |
| 5,000 –º–∏–Ω/–º–µ—Å | $155 | $80 | $75 (48%) |
| 10,000 –º–∏–Ω/–º–µ—Å | $280 | $140 | $140 (50%) |
| 50,000 –º–∏–Ω/–º–µ—Å | $1,150 | $500 | $650 (57%) |

**–ü—Ä–∏–º–µ—á–∞–Ω–∏—è:**
- Infrastructure costs –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç—Å—è –Ω–µ–ª–∏–Ω–µ–π–Ω–æ (–±–æ–ª—å—à–µ –æ–±—ä—ë–º = –º–µ–Ω—å—à–µ cost per minute)
- –ü—Ä–∏ >10K –º–∏–Ω—É—Ç/–º–µ—Å—è—Ü –º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å (committed use discounts)
- Redis cache hit rate –ø–æ–≤—ã—à–∞–µ—Ç—Å—è —Å –æ–±—ä—ë–º–æ–º ‚Üí –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —ç–∫–æ–Ω–æ–º–∏—è

### Key Technologies

‚úÖ **FFmpeg 8.0 "Huffman"** with Whisper.cpp integration
‚úÖ **Gemini 3 Flash** for text formatting
‚úÖ **Redis caching** for repeated content
‚úÖ **Firestore batching** for cost optimization
‚úÖ **Async pipeline** for parallelization

### Total Effort

- **Development:** 7-9 –Ω–µ–¥–µ–ª—å
- **Downtime:** 1-2 —á–∞—Å–∞ (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º)
- **Tests:** 100+ unit/integration tests
- **Documentation:** Comprehensive guides for AI agents

---

## üîó References

### Documentation
- [FFmpeg 8.0 Whisper Tutorial](https://www.rendi.dev/post/ffmpeg-8-0-part-1-using-whisper-for-native-video-transcription-in-ffmpeg)
- [FFmpeg Whisper Filter Docs](https://ayosec.github.io/ffmpeg-filters-docs/8.0/Filters/Audio/whisper.html)
- [Gemini 3 Documentation](https://ai.google.dev/gemini-api/docs/gemini-3)
- [Google Gen AI SDK](https://ai.google.dev/gemini-api/docs/changelog)
- [Firestore Optimization Guide](https://airbyte.com/data-engineering-resources/google-firestore-pricing)

### Source Code Locations
- **Main Plan:** `/GEMINI-plan.md` (this file)
- **Codebase:** `/telegram-whisper-bot/`
- **Audio Processor:** `/audio-processor-deploy/`
- **Tests:** `/audio-processor-deploy/tests/`
- **Documentation:** `/CLAUDE.md`, `/README.md`

---

## ‚úÖ Implementation Checklist for AI Agents

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç–æ—Ç checklist –¥–ª—è tracking –ø—Ä–æ–≥—Ä–µ—Å—Å–∞:

### Phase 1: FFmpeg 8.0 Whisper (2-3 weeks)
- [ ] Create Dockerfile with FFmpeg 8.0 + Whisper.cpp
- [ ] Download and integrate ggml-base.bin model
- [ ] Update AudioService.transcribe_audio()
- [ ] Remove OpenAI API dependency
- [ ] Update requirements.txt
- [ ] Deploy Docker container to Cloud Functions
- [ ] Run unit tests (test_ffmpeg_whisper.py)
- [ ] Run integration tests
- [ ] Performance benchmark (target <30s for 10-min)
- [ ] Quality verification (WER <10%)

### Phase 2: Gemini 3 Flash (1 week)
- [ ] Update google-genai to latest version
- [x] Change model to gemini-2.5-flash (Gemini 3 is not available in us-central1 for this project yet)
- [ ] Add thinking_level parameter
- [ ] Update prompt for Gemini 3
- [ ] A/B test quality vs Gemini 2.5
- [ ] Deploy to production
- [ ] Monitor performance (target 7-12s formatting)

### Phase 3: Architecture Optimizations (2-3 weeks)
- [ ] Implement async/await pipeline
- [ ] Setup GCP Memorystore Redis
- [ ] Implement Redis caching layer
- [ ] Batch Firestore writes
- [ ] Remove unnecessary gc.collect() calls
- [ ] Implement exponential backoff for rate limits
- [ ] Performance testing

### Phase 4: GCP Optimization (1 week)
- [ ] Set min_instances: 0 in app.yaml
- [ ] Update Cloud Scheduler for warmup
- [ ] Optimize Cloud Functions memory (512MB)
- [ ] Remove unused Firestore indexes
- [ ] Optimize Firestore queries
- [ ] Monitor cost savings

### Phase 5: Dependency Management (2-3 days)
- [ ] Pin all package versions
- [ ] Create requirements-lock.txt
- [ ] Document FFmpeg build configuration
- [ ] Create DEPENDENCIES.md

### Phase 6: Testing (2 weeks)
- [ ] Write unit tests (>70% coverage)
- [ ] Write integration tests
- [ ] Performance regression tests
- [ ] Quality assurance tests (WER)
- [ ] Smoke tests script

### Phase 7: Deployment (1 week)
- [ ] Pre-deployment checklist
- [ ] User notification (24h advance)
- [ ] Backup current version
- [ ] Deploy Cloud Function
- [ ] Deploy App Engine
- [ ] Post-deployment verification
- [ ] Setup monitoring dashboard
- [ ] Setup alerts
- [ ] Monitor for 48 hours
- [ ] Create performance report

---

**End of Plan. Ready for Implementation.**

---

**–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞:** 2.0
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2026-01-13
**–°—Ç–∞—Ç—É—Å:** Approved for Implementation
**–¶–µ–ª–µ–≤–∞—è –≤–µ—Ä—Å–∏—è:** v2.0.0
